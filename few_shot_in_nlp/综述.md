# 综述

### Meta-learning for Few-shot Natural Language Processing: A Survey

> ArXiv 2020.07.19	2021.08.02读

#### 知识点

- What is Meta-learning?

  对于一个文本分类任务，一般的做法是将一个句子和相应标注作为训练样本，而元学习则是以任务`tasks`作为训练样本。元学习假设训练的任务和测试中出现的新任务同分布。

- Meta-learning vs Transfer learning

  Meta-learning: 面向有益于目标应用场景的方向优化参数；假设训练任务和目标任务同分布，源任务选取更严格；元学习和多任务学习中的知识迁移是并行的。

  Transfer learning: 预训练时未考虑最终应用场景；可以在任何可能对目标任务有帮助的源任务上训练；迁移学习中的知识迁移是串行的。

- Meta-learning vs. Multi-task learning

  Meta-learning: 目标是学习一个高效学习算法，在目标任务上快速学习；元学习结果不会偏向数据量更大的任务；元学习将任务作为训练样本，任务越多，效果越好。

  Multi-task learning: 目标是学习一个在目标任务上效果好的预训练模型；多任务学习结果会偏向于训练数据量更大的任务；多任务学习会面临任务增长的挑战。

#### 可以看的引用

- Shumin Deng et al. Metalearning with dynamic-memory-based prototypical network for few-shot event detection. WSDM 2020.
- Viet Dac Lai et al. Exploiting the matching information in the support set for few shot event classification. PAKDD 2020.
- Timothy M. Hospedales et al. Meta-learning in neural networks: A survey. CoRR 2020.