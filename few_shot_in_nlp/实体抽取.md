### Simple and Effective Few-Shot Named Entity Recognition with Structure Nearest Neighbor Learning 

> EMNLP 2020

#### 知识点

- 不同于原型网络（每个`class`有一个平均向量，计算每个`token`到`class`的距离以分类），这篇论文使用有监督实体抽取模型在源域训练得到的`token embedding`，通过计算`test example`中`token`与支撑集中`token`的距离，将距离最小的支撑集`token`的`class`作为预测结果。距离计算公式为欧氏距离的平方。
- **STRUCTSHOT**：`Abstract transition probabilities` -> `Target transition probabilities`

#### 引用

- Alexander Fritzler et al. Few-shot classification in named entity recognition task. ACM/SIGAPP 2019.
- Yutai Hou et al. Few-shot slot tagging with collapsed dependency transfer and label-enhanced task-adaptive projection network. ACL 2020.



### Few-shot Slot Tagging with Collapsed Dependency Transfer and Label-enhanced Task-adaptive Projection Network

>ACL 2020

#### 知识点

- 提出**Collapsed Dependency Transfer Mechanism**，这是`STRUCTSHOT`中抽象`CRF`转移矩阵的由来。

- 改进TapNet，将其用于序列标注，通过计算原型向量$$c_j$$与参考向量$$\psi$$的`linear error nulling of alifnment error `（对齐误差的线性误差）来确定`Projection Space`$$M$$
  $$
  原型向量：c_j \\
  参考向量：\psi_j = (1 - \alpha) \cdot \phi_j + \alpha s_j
  $$
  其中：$$\phi_j$$为全局参考向量，提供跨域的概括信息；$$s_j$$为标签语义，提供域的特殊信息。
  
  `CRF`发射分数的计算：
  $$
  f_E(y_j, x, S) = Softmax\{SIM(M(E(x)), M(\Omega_j))\}, \\
  where \space\space \Omega_j = (1 - \beta) \cdot c_j + \beta \psi_j
  $$


#### 引用

- Sung Whan Yoon et al. Tapnet: Neural network augmented with task-adaptive projection for few-shot learning. ICML 2019.



### Few-shot classification in named entity recognition task. 

> ACM/SIGAPP 2019.

#### 知识点

- 将few-shot NER任务建模为半监督学习任务
- 更新原型网络以解决NER任务
  - Sequential vs independent objects
  - Class "no entity"
  - In-domain and out-of-domain training

#### 引用

- 无



### Few-shot Learning for Named Entity Recognition in Medical Text

> arXiv 2018. 2021.08.13 水文，未发表

#### 知识点

- 针对一些源于电子病历的数据集，实验设置：
  - 目标域，用于有监督训练和测试：i2b2 2009
  - 用于有监督预训练：i2b2 2010，i2b2 2012
  - 用于词向量的无监督训练：BioNLP-2016，MIMIC-III，UK CRIS
- 五个改进模型性能的方法：
  - Single pre-training：在另外三个大的数据集上分别进行NER预训练
  - Hyperparameter tuning：调参...这也可以写吗
  - Combined pre-training: 同一个模型使用三个大的数据集串行训练
  - **Customized word embeddings**：基于三个大的医疗数据集，使用fasttext训练词向量，可能能用到
  - Optimizing OOV words：删掉一些标点、引用啥的
- 这篇论文没啥用，水文一篇，就Customized word embedding如果开源了可以试一下，但是其实自己训练也很快

#### 引用

- 无



### Learning from Miscellaneous Other-Class Words for Few-shot Named Entity Recognition

> ACL 2021

#### 知识点

- 针对原型网络用于命名实体识别出现的O平均表示不准确的问题，提出了**Undefined Classes from Other-class (MUCO) Model**，主要有两个模块：
  - Undefined Classes Detection：识别O中的多种类别
    - 首先，根据预预定义类别的实体样本（除了O）训练一个原型网络
    - 基于训练好的原型网络和一个添加的映射对预定义类别的实体样本（除了O）训练分组分类器
    - 用这个分组分类器进行属于O的token的分组推断
  - Joint Classification：将属于O的token进行细粒度分组后再训练一个新的原型网络进行实体识别

#### 引用

- Liang Xu et al. Cluener2020: Fine-grained named entity recognition dataset and benchmark for chinese. ArXiv 2020. （一个中文数据集）



### Cluener2020: Fine-grained named entity recognition dataset and benchmark for chinese. 

> Arxiv 2020 一个中文数据集

#### 知识点

- 数据分布：训练集（10748）+ 验证集（1343），类别（10）
- 链接：https://github.com/CLUEbenchmark/CLUENER2020

#### 引用

无



### Leveraging Type Descriptions for Zero-shot Named Entity Recognition and Classification

> ACL 2021

#### 知识点

- 这篇论文是第一篇探索**zero-shot NERC**的论文

- **利用类型描述来解决少样本实体识别与实体分类问题**。这里的实体识别与分类是一个连续的任务：给定一个文本和实体类型集合，即要识别文本中的实体并判断这个实体属于哪类(如地点，人物等)，这里的实体类型集合可能是**变动的**。本文是要解决少样本来做此任务，具体解决方案是利用**实体类型的描述信息来表征成实体类型向量**，然后与实体向量进行匹配学习。

- **Sequential Multiclass Cross-attention Model (SMXM)**：通过对输入句子和实体类型描述进行**cross-attention encoder (X-ENC)**，线性变换后生成每个`token`对应的类的概率
  $$
  X-ENC的输入为(s,d_c)，被构造为以下形式：\\
  
  x_{X-ENC} = [CLS] \space s \space [SEP] \space d_c \space [SEP]
  $$
  

- 论文中提出的一种可行的针对`Other class`的解决方案：将训练集（测试时是测试集）所有出现的类的特征表示通过一个`Other class`专用的矩阵进行线性变换，之后进行`max-pooling`和另一次线性变换后得到每个`token`属于`Other class`的得分

#### 引用

- Ganesh Jawahar et al. What Does BERT Learn about the Structure of Language?  ACL 2019.



### Subsequence Based Deep Active Learning for Named Entity Recognition

> ACL 2021

#### 知识点



#### 引用

